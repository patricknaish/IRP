
\documentclass[12pt,journal,compsoc]{IEEEtran}


\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else

\fi

\usepackage{array}
\usepackage{hyperref}
\usepackage{url}
\usepackage[noadjust]{cite}
\usepackage{todonotes}

% correct bad hyphenation here
\hyphenation{ana-lysis}


\begin{document}

\title{Investigating the feasibility and worth of migrating legacy systems}
\author{Patrick~Naish~\\\texttt{pn3g10@zepler.net}}


\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
System modernisation has been a major concern for many businesses since the start of the decline in mainframe engineers. Those who were once responsible for the maintenance of complex and crucial large-scale systems have rapidly started to reach the age of retirement, and the majority of new engineers entering the workforce do not have the knowledge of legacy technologies necessary to maintain the systems in their current state. This paper explores the problem behind system modernisation, discussing various approaches, tools, and processes which have been developed to solve it. After presenting a comparison between these, a conclusion is drawn that the next step in the field must be to automate the analysis of systems in order to select an economical and appropriate approach for a given business.
\end{abstract}}

% Note that keywords are not normally used for peerreview papers.
%\begin{IEEEkeywords}
%Computer Society, IEEEtran, journal, \LaTeX, paper, template.
%\end{IEEEkeywords}}

\maketitle

\IEEEdisplaynotcompsoctitleabstractindextext

\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}

\IEEEPARstart{F}{or} at least forty years, mainframe computing has been the backbone of technological industry, to a greater or lesser extent. Despite having fallen out of favour in more recent years, in deference to the modern client-server style of computational interaction, mainframe software still underpins a vast amount of modern systems. There were an estimated 200 billion lines of COBOL in use in 2008 \cite{Datamonitor2008}, with no indication of a decline in its use. However, COBOL is widely considered to be a dead language, and the fact that young computer scientists are primarily taught languages such as Java \cite{Sneed2013} and Python means that many are unwilling to learn older languages such as COBOL or PL/I. Those developers who do know the languages required to maintain legacy mainframe systems are rapidly reaching the age of retirement and leaving the industry, making the continued use of mainframe systems in their current form impractical, or eventually even impossible.

One of the major challenges in redevelopment is noted by Sneed \cite{Sneed2011} in that, when replacing an application with which users have grown familiar, they expect the exact same functionality and features (and potentially new features on top of those). Because of this, he says, ``...it is much more difficult to replace an existing application than it is to develop one from scratch.'' \cite{Sneed2011}. Unfortunately, there is often a lack of resources (monetary and otherwise) available for redevelopment efforts. A 1996 case study \cite{Duncan1996} estimated that the cost of redeveloping the client's existing systems from scratch would cost approximately \$24 million, over four years (with twenty staff), totalling approximately ``...100 person years of effort...'' \cite{Duncan1996}. It is therefore evident that there is a need for a means by which to ease the effort of modernisation of legacy systems, without incurring unfeasibly large costs to the maintainers of said systems.

This paper will discuss the current available approaches to modernisation in \autoref{sec:approaches}, the issues which must still be addressed in the field in \autoref{sec:issues}, and draw a conclusion  in \autoref{sec:conclusion}.

\hfill May 8, 2014

\section{Approaches to modernisation}
\label{sec:approaches}

Almonaies et al. \cite{Almonaies2010} suggest four main approaches towards the modernisation of legacy systems:
\begin{itemize}
\item Replacement, in which one either rewrites existing applications in a modern language and style, or replaces them altogether (often ``...with an off the shelf product...'' \cite{Almonaies2010}).
\item Reengineering, in which reverse-engineering is used to add modern functionality into the legacy systems themselves.
\item Wrapping, in which an interface is developed to encapsulate the legacy components so that they may be accessed as services from other components.
\item Migration, in which the legacy system is transitioned into a new environment ``...while preserving the original system\'s data and functionality...'' \cite{Almonaies2010}.
\end{itemize}

Sneed \cite{Sneed2009} discusses this in terms of migration versus integration, where migration involves the actual transferral and/or transformation of code and components into a new environment. Integration instead refers to remotely accessing components from the new environment, without transitioning existing components into it.

As previously noted in \autoref{sec:introduction}, replacement is potentially either prohibitively expensive \cite{Duncan1996} or fails due to difficulties users experience in adopting the new software \cite{Sneed2011}. This is not to say it is never a practical option; for smaller-scale applications, replacement may well be the most cost-effective solution after analysis. For the most part, however, existing literature deals with migration \cite{Aversano2001,Bodhuin2002,Canfora2006,Canfora2000,Canfora2008,Lucia1997,Lewis2006,Sneed2011,Sneed2008,Sneed2009,Sneed2013,Wu2005,Sneed1996,Duncan1996}, with elements of wrapping \cite{Chiang2001,Canfora2008,Sneed1996,Sneed2003}.

The CelLEST project \cite{Stroulia2002} is discussed in the context of reengineering, although this still makes heavy use of wrapping. Distante et al. \cite{Distante2006} also discuss techniques for reengineering for the web.

\subsection{Service-Oriented Architectures}
\label{subsec:soa}
The most popular architecture to which legacy systems are migrated is that of a Service-Oriented Architecture (SOA) \cite{Sneed2008,Almonaies2010,Koschel2009,Canfora2006,Sneed2009,Canfora2008}. A service is defined by Perrey and Lycett \cite{Perrey2003} as ``...the boundary between a consumer understandable value proposition and a technical implementation...''. That is to say, it provides an interface between an agent and a layer providing functionality to allow for interaction, without necessitating a deep understanding of underlying code. SOA is, therefore, a design pattern based on the interaction between these services.

Some of the advantages of SOA for the purposes of migrating legacy systems are its flexibility, reusability and abstraction \cite{Almonaies2010}. As Aversano et al. note \cite{Aversano2001}, the mainframe systems were largely built before the internet became prevalent, using a centralised architecture. The need for the benefits provided by SOAs has lead to an effort to maintain the value of investments in traditional system architectures, while still providing the modern interaction patterns one would expect. Accommodating a new architecture on the legacy systems themselves would involve a significant time and effort investment, and may not be feasible without comprehensive documentation of the existing system.

\subsection{Tools for code analysis}
\label{subsec:toolsanalysis}
One of the main tasks in migrating systems is to analyse code for elements which can be extracted and encapsulated, as well as judging the feasibility of migrating a certain piece of code. This would be prohibitively complex (and therefore time-consuming and costly) for a human to perform manually, so tools have been developed to do so automatically (as far as possible).

Sneed \cite{Sneed2009} uses the COBAudit tool to assess a large volume of programs in his pilot project. This took ``...56 different size measurements...'' \cite{Sneed2009} from each program, including lines of code and number of data structures. From these, eight metrics were used to determine the programs' overall complexities (as discussed by Sneed in a 1995 paper \cite{Sneed1995}). These complexity measurements are then normalised using SoftAudit, with values above 0.5 indicating high complexity, and those below indicating low complexity. Any values over 0.8 can be considered to indicate extreme complexity. From the normalised results, it is then possible to select programs which are suitable for reuse, as well as identify the sections of them for which this will be most straightforward or difficult.

Lewis et al. \cite{Lewis2005a} use the Understand for C++ tool to extract both a static analysis of a C++ application, and metrics for assessing the ease of migration. They then use the Architecture Reconstruction and Mining (ARMIN) \cite{O'Brien2005} tool to attempt to reconstruct the architecture of analysed programs, in order to find inter-service dependencies (as well as issues with these dependencies in their current form). This analysis is then used to create a migration strategy moving forward.

\subsection{Tools for migration}
\label{subsec:toolsmigration}
Once reusable code has been identified, there are various tools available for facilitating migration. One set of these tools is COB2WEB, created by Sneed \cite{Sneed2008}, comprising COBStrip, COBWrap, and COBLink, as well as the COBAudit tool mentioned in \autoref{subsec:toolsanalysis}.

\subsubsection{COBStrip}
\label{subsubsec:cobstrip}
This tool uses code slicing to decompose programs \cite{Canfora2000}. This concept is discussed in some detail by Weiser \cite{Weiser1984}, and applied practically in the context of migration by Sneed \cite{Sneed2009,Sneed2008}. Its purpose is to separate out various `slices' from a program, where each slice represents a path through the program that will perform a given function of the original code. These slices are used to ``...generate multiple instances of the same program...'' \cite{Sneed2009,Sneed2008}, which can then be run as individual web services. The tool requires some user interaction, but reduces the workload of slicing significantly.

\subsubsection{COBWrap}
\label{subsubsec:cobwrap}
This tool uses the stripped programs generated by COBStrip, and replaces input/output (I/O) operations with ``...calls to a wrapper module...'' \cite{Sneed2009,Sneed2008}, as well as moving required data to the correct sections of the program. This can be performed without any user interaction, as it is a reasonably simple operation when used with predictable programmatic structures (such as those in COBOL).

\subsubsection{COBLink}
\label{subsubsec:coblink}
This tool uses the wrapped programs generated by COBWrap, and creates Web Services Description Language (WSDL) \cite{Christensen2001} interfaces for both incoming requests and outgoing responses, as well as COBOL modules for translating between the WSDL and COBOL parameters. This process has been described by Sneed in detail \cite{Sneed2001}, as well as applied in a practical application \cite{Sneed2009,Sneed2008}. Once these are generated, it is possible to interact with the services with Simple Object Access Protocol (SOAP) \cite{Gudgin2013} messages, thereby accessing the functionality of the legacy application through a modern, flexible interface.

\subsection{Techniques and approaches}
\label{subsec:techniques}
Due to the maturity of both mainframe systems and the more modern SOA, there has been a lot of time dedicated to exploring techniques for applying modernisation tools and practices to real-world systems. Some of these are purely theoretical, whereas others have been tested in practice.

\subsubsection{Service-Oriented Migration and Reuse Technique (SMART)}
\label{subsubsec:smart}
SMART was described by Lewis et al. as a ``...process for evaluating legacy components for their potential to become services...'' \cite{Lewis2005,Lewis2005a}. As opposed to the tools mentioned in \autoref{subsec:toolsanalysis} and \autoref{subsec:toolsmigration}, this is a set of in-depth analyses of various aspects of the legacy system, target environment, user base, and effort requirements. This is something more of a software engineering approach than a computer science one, as it involves considering the business as a whole and developing strategies, rather than only considering the technical challenge involved. This, of course, leads to a larger amount of work needing to be performed initially, but creates a more cohesive strategy for the overall migration process.

Part of this process may also involve architecture reconstruction, using a tool such as ARMIN (previously mentioned in \autoref{subsec:toolsanalysis}). This allows for analysis of Rigi Standard Format (RSF) \cite{Kienle2010} files, containing metadata extracted from source files in various languages \cite{O'Brien2005}. These analyses are used to create models and abstractions which, in turn, ``...produce higher-levels[\textit{sic}] models and views...'' \cite{O'Brien2005}. Eventually, through this process, the ``...desired set of views is produced.'' \cite{O'Brien2005} An evident use of this is to separate out a legacy application into Model--View--Controller (MVC) layers, as additionally discussed by Bodhuin et al. \cite{Bodhuin2002}.

\subsubsection{Service-Oriented Software Reengineering Methodology (SoSR)}
\label{subsubsec:sosr}
SoSR was proposed by Chung et al. as an ``...architecture-centric, service-oriented, role-specific and model-driven'' \cite{Chung2007} methodology for software reengineering. It uses a `4+1 view model', where a system is considered to be composed of four primary views:
\begin{itemize}
\item Design view
\item Implementation view
\item Process view
\item Deployment view
\end{itemize}
which share a single use case view. The use case view represents the software engineering aspects of the system architecture, such as user requirements; the four primary views represent the logical, physical, static, and dynamic aspects of the overall system. It also makes use of Responsible, Accountable, Consulting, and Informed (RACI) charts \cite{Smith2005} to show the tasks required for each role in the system.

\subsubsection{Ubiquitous Web Applications Design Framework (UWA)}
\label{subsubsec:uwa}
UWA \cite{UWAConsortium2002} and the Extended UWA Transaction Design Model (UWAT+) \cite{Distante2005} are discussed by Distante et al. \cite{Distante2006} as a means to reengineer legacy systems. As with SoSR (\autoref{subsubsec:sosr}) and SMART (\autoref{subsubsec:smart}), this deals not only with the technical aspect of system modernisation, but also the software engineering aspects such as requirement gathering. UWAT+ has the concept of ``...Web transaction[s]...'' \cite{Distante2006}, which are a set of user interactions required to complete a given task.

This relies fairly heavily on reverse-engineering to generate `meta-models', which can then be used to generate more concrete models in turn. From these, a web version of the original system can be engineered.

A case study of the technique in use can be seen in the report by Distante et al. \cite{Distante:2006:RLA:1134285.1134353}.

\subsubsection{CelLEST}
\label{subsubsec:cellest}
The CelLEST project \cite{Stroulia2000} deals mostly with front-end interfaces, and user interactions with them, for a given system. Stroulia et al. \cite{Stroulia2002} discuss that, as opposed to techniques based on gaining an understanding of the original application's architecture through code analysis, CelLEST constructs a model of the behaviour of the legacy system through analysing user-interface interaction paths. This model is then used as an interface between users and the legacy application (i.e. wrapping legacy components), without modifying the original code.

Because of the nature of the analysis, this requires a large amount of user interaction, ideally by ``an expert user of the legacy application'' \cite{Stroulia2002}. However, it does not require the full software-engineering processes that are used by techniques such as SMART (\autoref{subsubsec:smart}). Stroulia et al. note that this technique cannot be used for maintenance, as it does not modify the underlying code, but is a means of providing access to said code through a modern interface.

\subsubsection{Finite State Automata (FSA)}
Canfora et al. \cite{Canfora2006,Canfora2008} discuss the usage of FSA to model the interactions between a user and the legacy system, on the basis that a traditional purely `black-box' approach to wrapping will not be aware of the current state of the legacy system when executing a command, which may lead to unknown behaviour (a problem exacerbated by the scaling of the number of users simultaneously accessing a system, from the mainframe to SOA). Thus, the automaton for a given system will keep track of the current state of the underlying system, and model the currently available I/O operations through a wrapper layer. Paths through the automaton can be identified in a similar manner to code slicing (\autoref{subsubsec:cobstrip}), and used to assess whether all the scenarios for a given operation have been accounted for.

\subsection{Summary}
\label{subsec:summary}

\autoref{table:approaches} shows a simplified overview of the four main approaches to modernisation discussed in \autoref{sec:approaches}. For each of these approaches, it is possible to provide a typical cost and effort estimate. However, providing a general assessment of the effectiveness of each technique is impossible for such broad categories. In order to break these categories down somewhat, \autoref{table:tools} summarises the tools discussed in \autoref{subsec:toolsanalysis} and \autoref{subsec:toolsmigration}, while \autoref{table:techniques} summarises the techniques for modernisation discussed in \autoref{subsec:techniques}. Of the five techniques discussed, only SoSR has not been tested in a case study.

\begin{table}[h!]
\caption{Comparison of the four main approaches to modernisation}
\label{table:approaches}
\centering
\begin{tabular}{| l | c | c |}
  \hline
  \textbf{Approach} & \textbf{Cost} & \textbf{Effort} \\ \hline
  Replacement & High & Moderate \\ \hline
  Reengineering & Moderate & High \\ \hline
  Wrapping & Low & Low \\ \hline
  Migrating & Moderate/High & Moderate \\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Comparison of tools for modernisation}
\label{table:tools}
\centering
\begin{tabular}{| l | c | c |}
  \hline
  \textbf{Tool} & \textbf{Category} & \textbf{Compatibility} \\ \hline
  COBAudit & Analysis & COBOL \\ \hline
  SoftAudit & Analysis & General \\ \hline
  Understand for C++ & Analysis & C++ \\ \hline
  ARMIN & Analysis & General \\ \hline
  COBStrip & Migration & COBOL \\ \hline
  COBWrap & Migration & COBOL \\ \hline
  COBLink & Migration & COBOL \\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Comparison of specialised techniques for modernisation}
\label{table:techniques}
\centering
\begin{tabular}{| l | c | c |}
  \hline
  \textbf{Technique} & \textbf{Category} & \textbf{Maturity} \\ \hline
  SMART & Evaluation & Case study \\ \hline
  SoSR & Reengineering & Proposed \\ \hline
  UWA & Reengineering & Case study \\ \hline
  CelLEST & Wrapping & Case study \\ \hline
  FSA & Wrapping & Case study \\ \hline
\end{tabular}
\end{table}

These do not represent an exhaustive list of the available tools and techniques, but those which are most well-documented. Additionally, most of these techniques (along with the required tools) have been applied to real-world problems, except for SoSR. It is important to note that the cost and effort measures for the approaches to modernisation are exemplar of those a typical mid-sized enterprise might find they incur. Additionally, the effort of replacement depends on whether the system is replaced by an in-house development team or using an off-the-shelf product.

\section{Issues which must be addressed}
\label{sec:issues}
Even with the currently available tools and techniques, the problem of modernising legacy systems is far from solved. The main issues which present themselves are those discussed below:
\begin{itemize}
\item Cost-effectiveness
\item Maintainability
\item Automation
\end{itemize}
as well as more human issues such as user-acceptance and the necessity for retraining. It is also important to consider that, in a real-world business scenario, deployment of new systems must be approached gradually in order to not disrupt current operation \cite{Sneed2008,Duncan1996,Almonaies2010}. This in and of itself adds another dimension of complexity to the entire effort of modernisation.

\subsection{Cost-effectiveness}
\label{subsec:costeffectiveness}
The best example of cost-effective migration was discussed in \autoref{sec:introduction}, with the case study from Duncan et al. \cite{Duncan1996} showing an estimated \$24 million cost for redevelopment, as opposed to a \$4.8 million cost for migration (including hardware, software, training and operating costs) over three years. Additionally, there was a benefit to the company of \$9.45 million over that same three year period, due to the improvements made during modernisation.

Although this was a success, the lower cost was due to the overall complexity of the systems that required modernisation. With a less complex legacy system, the effort required to redevelop may be significantly less than the effort required to migrate or reengineer. This falls, therefore, to analysts to determine the most appropriate course of action -- but even this brings its own expenses and consumes resources.

\subsection{Maintainability}
\label{subsec:maintainability}
While some of the approaches do not even attempt to deal with the issue of maintainability \cite{Stroulia2002}, most make some attempt to ease further development. This is achieved by updating the original code and wrapping it in a modern language, transforming the original code into a more modern language, or some combination of the two. The rationale is that younger computer scientists and software engineers will be more familiar with languages such as Java \cite{Sneed2013}, and therefore will be able to continue maintaining the software moving forwards.

This does not deal with the fact that design patterns have changed significantly even over the last twenty years, let alone forty, and modernisation is something of a stopgap solution to updating systems. It could be considered that the entire exercise is in striking a balance between cost and maintainability, in that a larger expenditure will most likely leave you with a more modern and maintainable solution. Obviously this is not always feasible or even appropriate for a smaller business, but it is important to remember that no system can be maintained indefinitely while competing successfully against more modern alternatives. It may also be the case that redeveloped software will better suit an organisation's needs.

Maintaining a system without a deep understanding of it also presents some issues. Lack of familiarity introduces more complexity into maintaining it, especially when one is now required to not only understand the modern and legacy code (where it remains), but also the interactions between them. However, a similar argument for lack of familiarity could be made against entirely replacing an existing system \cite{Almonaies2010}.

\subsection{Automation}
\label{subsec:automation}
The tools discussed in \autoref{subsec:toolsmigration} and \autoref{subsec:toolsanalysis} are a step towards automating the modernisation process, thereby reducing the costs required to do so. However, due to the varied and complex nature of legacy systems, it is extremely difficult to fully automate many steps. Sneed has made many steps towards automating the process as far as possible for certain languages \cite{Sneed2013,Sneed2011,Sneed2008,Sneed2009,Sneed1996,Sneed2001}, as have other researchers \cite{Deursen1998,Aversano2001,Chiang2001,Wu2005,O'Brien2005,Distante2006}, but the problem is far from solved. It may be the case that this is an issue which may never be fully overcome, as there is an almost infinite number of potential edge cases for any software, but it does at least pave the way for automation as far as possible.

\section{Conclusion}
\label{sec:conclusion}
Having seen the available solutions to the problem of modernisation, and the available tools and techniques, it becomes apparent that despite the breadth of resources and knowledge there is no universally applicable process available. Whereas for one business, reengineering a system may be prohibitively expensive and time-consuming such that the preferred solution is to wrap existing systems and gradually phase them out, another may find that wrapping is too transitory to be cost-effective, and that they have the resources (for example, original system design documents) to make reengineering viable.

The challenge that must be overcome in order to effectively utilise appropriate solutions for businesses is, therefore, that of efficiently determining which approach will be most feasible -- and, indeed, whether it would be more economical to continue to use existing systems until the point where it is demonstrably impacting the business, then replacing it entirely rather than attempt modernisation. While some of the processes go some way toward answering this problem, as mentioned in \autoref{sec:issues} there are issues of both cost and a lack of existing automation in any available processes.

If future work in the field strives to improve the power of tools and processes for selecting a modernisation strategy for a given system, reducing the need for human analysis, it will become significantly more economically viable to start the modernisation effort proper. Given the concerns addressed in \autoref{sec:introduction} adding a time pressure, and considering the quality of the tools for the actual modernisation processes available, a focus on developing low-effort means of analysis of businesses should be prioritised.

It is also worth noting that, while there are some high-quality tools and processes available, they are often quite specialised to a purpose or language. It may therefore be worth exploring the creation of a more general tool (although ARMIN \cite{O'Brien2005} already accomplishes this to some degree, it is far from general-purpose). Making these tools more accessible to the layman would also lower training costs, although given the importance of the process this should not be at the expense of functionality.

Overall, the work in the field has been progressing well, but requires a final layer of consideration before it is truly practical for an arbitrary business to make an informed decision on the best option for their circumstance. Once this is in place, the problem of modernisation of systems may be said to be at least somewhat solved.

\appendices
%\section{Proof of the First Zonklar Equation}
%Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
%\section{}
%Appendix two text goes here.


% use section* for acknowledgement
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgements}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgement}
\fi

The author would like to thank Prof. Michael Butler and Dr. Robert Walters for their supervision and feedback during the writing of this paper.


\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}

% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{biography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


